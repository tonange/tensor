{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print (tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47040000\n",
      "60000\n",
      "7840000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(linewidth=200)\n",
    "\n",
    "print(training_images.size)\n",
    "print(training_labels.size)\n",
    "\n",
    "print(test_images.size)\n",
    "print(test_labels.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0   0   1   4   0   0   0   0   1   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62  54   0   0   0   1   3   4   0   0   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134 144 123  23   0   0   0   0  12  10   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178 107 156 161 109  64  23  77 130  72  15]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216 216 163 127 121 122 146 141  88 172  66]\n",
      " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229 223 223 215 213 164 127 123 196 229   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228 235 227 224 222 224 221 223 245 173   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198 180 212 210 211 213 223 220 243 202   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192 169 227 208 218 224 212 226 197 209  52]\n",
      " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203 198 221 215 213 222 220 245 119 167  56]\n",
      " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240 232 213 218 223 234 217 217 209  92   0]\n",
      " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219 222 221 216 223 229 215 218 255  77   0]\n",
      " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208 211 218 224 223 219 215 224 244 159   0]\n",
      " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230 224 234 176 188 250 248 233 238 215   0]\n",
      " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223 255 255 221 234 221 211 220 232 246   0]\n",
      " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221 188 154 191 210 204 209 222 228 225   0]\n",
      " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117 168 219 221 215 217 223 223 224 229  29]\n",
      " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245 239 223 218 212 209 222 220 221 230  67]\n",
      " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216 199 206 186 181 177 172 181 205 206 115]\n",
      " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191 195 191 198 192 176 156 167 177 210  92]\n",
      " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209 210 210 211 188 188 194 192 216 170   0]\n",
      " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179 182 182 181 176 166 168  99  58   0   0]\n",
      " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(training_labels[0])\n",
    "print(training_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ae9d0f7308>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUDklEQVR4nO3da2yc1ZkH8P8z4/ElzjiJc3FCcAmXUJLCEqhJgFSUkkJDtNqQUioQYkFCG7QL3bbLBxDtquyXFUILCC277RrIElaFqlVBUBRRgrlkgZLGhJTcNgQSk5tjOzGxHcdjz+XZDx5aE3ye18w7M+/A+f8ky/Y8PjPHM/77nZnznnNEVUFEX36xqDtAROXBsBN5gmEn8gTDTuQJhp3IE1XlvLFqqdFa1JfzJom8ksIgRnRYxquFCruILAfwMIA4gMdU9T7r52tRjyWyLMxNEpFho7Y5awU/jReROID/AHA1gIUAbhCRhYVeHxGVVpjX7IsBfKCqe1R1BMCvAKwsTreIqNjChH0ugP1jvj+Qv+xTRGS1iLSLSHsawyFujojCCBP28d4E+My5t6raqqotqtqSQE2ImyOiMMKE/QCA5jHfnwrgULjuEFGphAn7JgDzReR0EakGcD2A54vTLSIqtoKH3lQ1IyJ3APg9Rofe1qjq9qL1jIiKKtQ4u6quA7CuSH0hohLi6bJEnmDYiTzBsBN5gmEn8gTDTuQJhp3IEww7kScYdiJPMOxEnmDYiTzBsBN5gmEn8gTDTuSJsi4lTRGQcVcV/ouQG3vGpzea9Y+/c7az1vDU26FuO+h3k6qEs6bpkXC3HVbQ42Ip8DHjkZ3IEww7kScYdiJPMOxEnmDYiTzBsBN5gmEn8gTH2b/kJB4365rJmPXYInuvzp23TbbbD7lricHFZtuqoZxZT7zUbtZDjaUHjeEH3K8Q+zgapm9SZcTWeDh5ZCfyBMNO5AmGncgTDDuRJxh2Ik8w7ESeYNiJPMFx9i85c0wWwePs+78z1azfeMn/mvU3e85w1j6qmW221TqzjKpvX2LWz/7Pg85apmOffeUBc8aD7rcg8WnT3MVs1myb7e93F41uhwq7iHQAGACQBZBR1ZYw10dEpVOMI/u3VPVIEa6HiEqIr9mJPBE27ArgJRF5R0RWj/cDIrJaRNpFpD2N4ZA3R0SFCvs0fqmqHhKRWQDWi8j/qeqGsT+gqq0AWgGgQRrDrW5IRAULdWRX1UP5z90AngVgT2MiosgUHHYRqReR5CdfA7gKwLZidYyIiivM0/gmAM/K6LzfKgBPqeqLRekVFU0ulQrVfuSC42b9e1PsOeW1sbSz9nrMnq9+8JVms579K7tvHz2YdNZy715qtp2+zR7rbni306wfuWyuWe/5uvsVbVPAcvrTXv7QWZNed6QLDruq7gFwfqHtiai8OPRG5AmGncgTDDuRJxh2Ik8w7ESeEA25Ze/n0SCNukSWle32vGEtexzw+B7//sVm/eqfvmbWF9QeMusDuVpnbUTDncD5yK5vmvXBPVOctdhIwJbJAeVsk70UtKbt4+i0ze7fvW5ll9lWHp3prL3X9jCO9+4ft/c8shN5gmEn8gTDTuQJhp3IEww7kScYdiJPMOxEnuA4eyUI2B44lIDH99x37P/3351mT2ENEjfWNh7UarPtsWx9qNvuybinuKYDxvgf221PgT1ujOEDQCxjP6ZXfutdZ+3axk1m2/vPPM9Z26ht6NdejrMT+YxhJ/IEw07kCYadyBMMO5EnGHYiTzDsRJ7gls2VoIznOpxs9/FZZv1ow2Szfjgz1axPj7uXe07Ghsy28xL2fqE9Wfc4OgDEE+6lqkc0brb9l6/9zqynFiTMekLspagvNdYBuG7H35pt67HHrLvwyE7kCYadyBMMO5EnGHYiTzDsRJ5g2Ik8wbATeYLj7J6bWWNve1wr7i2XAaBaMmb9UHqas7Z76Ktm2/f77XMAljdtN+tpYyzdmmcPBI+Tn5L42Kyn1B6Ht+7VpU32OPoWs+oWeGQXkTUi0i0i28Zc1igi60Vkd/6z+xElooowkafxTwBYftJldwNoU9X5ANry3xNRBQsMu6puANB70sUrAazNf70WwDXF7RYRFVuhb9A1qWonAOQ/O19cichqEWkXkfY0hgu8OSIKq+Tvxqtqq6q2qGpLAjWlvjkicig07F0iMgcA8p+7i9clIiqFQsP+PICb81/fDOC54nSHiEolcJxdRJ4GcDmAGSJyAMDPANwH4NciciuAfQCuK2Unv/QC1o2XuD33WjPuse74NHtU9JtTt5r1nmyDWT+WnWTWp8ZPOGsDGffe7QDQO2Rf9zk1nWZ984l5ztrManuc3Oo3AHSMzDDr82sOm/X7u9z7JzTXnvx++Kdlll3mrOnGPzhrgWFX1RscJe72QPQFwtNliTzBsBN5gmEn8gTDTuQJhp3IE5ziWgkClpKWKvthsobe9t+6wGx7xSR7yeS3UnPN+syqAbNuTTOdU9Nntk02pcx60LBfY5V7+u5Ats5sOylmn9od9HtfWG0vg/3jly901pLnHjXbNiSMY7QxissjO5EnGHYiTzDsRJ5g2Ik8wbATeYJhJ/IEw07kCY6zVwBJVJv1XMoeb7bM2Dpi1o9k7SWPp8bsqZ7VAUsuW1sjX9q412zbEzAWvnnodLOejLu3hJ4Zs8fJmxP2WPfWVLNZXzd4llm/9a9fdtaebr3SbFv94lvOmqj78eKRncgTDDuRJxh2Ik8w7ESeYNiJPMGwE3mCYSfyxBdrnN1Yclmq7PFiiQf8X4vZ9VzKmN+cs8eag2jaHgsP4+H/esSs789MNeuH03Y9aMnlrDHB+u2hKWbb2pi9XfTMqn6z3p+zx+ktAzl7mWtrnj4Q3Pe7pu921p7p+7bZtlA8shN5gmEn8gTDTuQJhp3IEww7kScYdiJPMOxEnqiocfYw66MHjVWrPewZqaGVi836/mvscfwbL/ijs3Y4kzTbvmtsawwAU4w54QBQH7C+ekrd5z8cGrG3kw4aq7bWhQeAWcY4fFbt49zBtN23IEHnHxzIGGva/409137qkwV1KfjILiJrRKRbRLaNuexeETkoIlvyHysKu3kiKpeJPI1/AsDycS5/SFUX5T/WFbdbRFRsgWFX1Q0AesvQFyIqoTBv0N0hIu/ln+Y7X+CIyGoRaReR9jTs13dEVDqFhv3nAM4EsAhAJ4AHXD+oqq2q2qKqLQnUFHhzRBRWQWFX1S5VzapqDsCjAOy3k4kocgWFXUTmjPl2FYBtrp8losoQOM4uIk8DuBzADBE5AOBnAC4XkUUAFEAHgNuK0RlrHD2sqjmzzXr69Caz3rvAvRf4idnGptgAFq3YadZvafpvs96TbTDrCTH2Z09PN9teMKnDrL/St9CsH6mabNatcfpL691zugHgWM7ef/2Uqo/N+l0ffM9Za5pkj2U/dpo9wJTWnFnflbZfsvbl3PPh/3Hhq2bbZzHTrLsEhl1Vbxjn4scLujUiigxPlyXyBMNO5AmGncgTDDuRJxh2Ik9U1BTX4asvMuuzfrLHWVvUcMBsu7DuDbOeytlLUVvTLXcMzTXbnsjZWzLvHrGHBfsy9hBUXNzDQN0j9hTXB/bayxa3Lf6FWf/pofHmSP1FrE6dtaNZe9ju2sn2UtGA/Zjd9pUNztoZ1d1m2xcG55j1QwFTYJsSfWZ9XqLHWftu8n2zbaFDbzyyE3mCYSfyBMNO5AmGncgTDDuRJxh2Ik8w7ESeKO84u9jLRS/5101m82XJ7c7aCbWnFAaNoweNm1qmVNnLBg+n7bu5O21PYQ1yds1hZ21Vwxaz7YZHlpj1b6R+YNY/vMKents25J7K2ZOxf+/r915h1jfvazbrF8/b66ydlzxotg06tyEZT5l1a9oxAAzm3H+vb6fs8w8KxSM7kScYdiJPMOxEnmDYiTzBsBN5gmEn8gTDTuQJUXXPNy62utnNeuZN/+Sst97+72b7p3ovdtaaa+3t6E6rPmLWp8ft7X8tyZg95vrVhD3m+sLgqWb9tWPnmPWvJzuctYTY2z1fPukDs37Lj+8065laexnt/nnu40mm3v7bazj/qFn/wVmvmPVq43c/lrXH0YPut6AtmYNYaxAkY/Y22Q+sWOWs/aHjCfQNdY77oPDITuQJhp3IEww7kScYdiJPMOxEnmDYiTzBsBN5oqzz2WNpYFKXe3zxhf5FZvsz6txrbR9J2+uj//74eWb91Dp7+19r6+GzjPnkALAlNdWsv9jzNbN+Sp29fnpXeoqzdjRdb7Y9YcyrBoDHH3rQrD/QZa87v6pxs7N2frU9jn4sZx+LdgSstz+Qq3XWUmqvb9AXMA6fNP4eACCtdrTixpbPU2P2GH7/ee5tuLNd7tsNPLKLSLOIvCoiO0Vku4j8MH95o4isF5Hd+c+Fr/5ARCU3kafxGQB3quoCABcDuF1EFgK4G0Cbqs4H0Jb/nogqVGDYVbVTVTfnvx4AsBPAXAArAazN/9haANeUqI9EVASf6w06EZkH4AIAGwE0qWonMPoPAcAsR5vVItIuIu2Z4cGQ3SWiQk047CIyGcBvAfxIVYN23PszVW1V1RZVbamqsd8sIqLSmVDYRSSB0aD/UlWfyV/cJSJz8vU5AOxtMYkoUoFDbyIiAB4HsFNVx47DPA/gZgD35T8/F3Rd8ZEckvuHnfWc2tMlXzninurZVDtgtl2U3G/Wd52wh3G2Dp3irG2u+orZti7u3u4ZAKZU21Nk66vc9xkAzEi4f/fTa+z/wdY0UADYlLJ/t7+f+ZpZ35dxD9L8bvBss+2OE+77HACmBSzhvbXf3f5Ext5GezhrRyOVsYdyp9TYj+lFjR85a7tgbxfdc74xbfhNd7uJjLMvBXATgK0isiV/2T0YDfmvReRWAPsAXDeB6yKiiASGXVXfAOA65C4rbneIqFR4uiyRJxh2Ik8w7ESeYNiJPMGwE3mivFs2Hx9C7PV3neXfvLTUbP7PK3/jrL0esNzyC4ftcdH+EXuq58xJ7lN9G4xxbgBoTNinCQdt+VwbsP3vxxn3mYnDMXsqZ9Y50DLq8LB7+iwAvJmbb9bTOfeWzcNGDQg+P6F3ZIZZP6Wuz1kbyLinvwJAx0CjWT/SZ2+rnJpkR+uN7JnO2vLZ7q3JAaCu2/2YxYw/FR7ZiTzBsBN5gmEn8gTDTuQJhp3IEww7kScYdiJPlHXL5gZp1CVS+ES5vhvdWzaf8Q+7zLaLp+4165v77Xnb+4xx13TAkseJmHvZYACYlBgx67UB483Vcfec9BjsxzcXMM5eH7f7FjTXvqHKPa87GbfnfMeMbY0nIm787n/smxfqupMBv3dG7b+JS6Z86Kyt2Xup2XbKCvc22xu1Df3ayy2biXzGsBN5gmEn8gTDTuQJhp3IEww7kScYdiJPlH+cPX6V+wdy9hrmYQxeu8SsL7lnk11PusdFz6nuMtsmYI8X1waMJ9fH7LHwlPEYBv03f2Oo2axnA67hlY8XmPW0Md7cdaLBbJswzh+YCGsfgqFMwJbNQ/Z893jMzk3qNXuu/fQd7nMnatbZf4sWjrMTEcNO5AuGncgTDDuRJxh2Ik8w7ESeYNiJPBE4zi4izQCeBDAbQA5Aq6o+LCL3Avg7AD35H71HVddZ1xV2PnulkovsNemHZteZ9Zqj9tzogdPs9g0futeljw3ba87n/rTTrNMXizXOPpFNIjIA7lTVzSKSBPCOiKzP1x5S1X8rVkeJqHQmsj97J4DO/NcDIrITwNxSd4yIiutzvWYXkXkALgCwMX/RHSLynoisEZFpjjarRaRdRNrTsJ+uElHpTDjsIjIZwG8B/EhV+wH8HMCZABZh9Mj/wHjtVLVVVVtUtSUBez81IiqdCYVdRBIYDfovVfUZAFDVLlXNqmoOwKMAFpeum0QUVmDYRUQAPA5gp6o+OObyOWN+bBWAbcXvHhEVy0TejV8K4CYAW0VkS/6yewDcICKLACiADgC3laB/Xwi6aatZtydLBmt4q/C24RZjpi+Tibwb/wYw7uLi5pg6EVUWnkFH5AmGncgTDDuRJxh2Ik8w7ESeYNiJPMGwE3mCYSfyBMNO5AmGncgTDDuRJxh2Ik8w7ESeYNiJPFHWLZtFpAfAR2MumgHgSNk68PlUat8qtV8A+1aoYvbtNFWdOV6hrGH/zI2LtKtqS2QdMFRq3yq1XwD7Vqhy9Y1P44k8wbATeSLqsLdGfPuWSu1bpfYLYN8KVZa+RfqanYjKJ+ojOxGVCcNO5IlIwi4iy0Vkl4h8ICJ3R9EHFxHpEJGtIrJFRNoj7ssaEekWkW1jLmsUkfUisjv/edw99iLq270icjB/320RkRUR9a1ZRF4VkZ0isl1Efpi/PNL7zuhXWe63sr9mF5E4gPcBXAngAIBNAG5Q1R1l7YiDiHQAaFHVyE/AEJHLABwH8KSqnpu/7H4Avap6X/4f5TRVvatC+nYvgONRb+Od361ozthtxgFcA+AWRHjfGf36Pspwv0VxZF8M4ANV3aOqIwB+BWBlBP2oeKq6AUDvSRevBLA2//VajP6xlJ2jbxVBVTtVdXP+6wEAn2wzHul9Z/SrLKII+1wA+8d8fwCVtd+7AnhJRN4RkdVRd2YcTaraCYz+8QCYFXF/Tha4jXc5nbTNeMXcd4Vsfx5WFGEfbyupShr/W6qqFwK4GsDt+aerNDET2sa7XMbZZrwiFLr9eVhRhP0AgOYx358K4FAE/RiXqh7Kf+4G8Cwqbyvqrk920M1/7o64P39WSdt4j7fNOCrgvoty+/Mowr4JwHwROV1EqgFcD+D5CPrxGSJSn3/jBCJSD+AqVN5W1M8DuDn/9c0AnouwL59SKdt4u7YZR8T3XeTbn6tq2T8ArMDoO/IfAvhJFH1w9OsMAH/Kf2yPum8Ansbo07o0Rp8R3QpgOoA2ALvznxsrqG//A2ArgPcwGqw5EfXtGxh9afgegC35jxVR33dGv8pyv/F0WSJP8Aw6Ik8w7ESeYNiJPMGwE3mCYSfyBMNO5AmGncgT/w866iIlnq8zVgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(training_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images  = training_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.53787005e-05\n",
      "  0.00000000e+00 0.00000000e+00 1.99923106e-04 1.12264514e-03 0.00000000e+00 0.00000000e+00 1.53787005e-05 6.15148020e-05 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.53787005e-05\n",
      "  1.53787005e-05 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 4.61361015e-05\n",
      "  0.00000000e+00 5.53633218e-04 2.09150327e-03 1.95309496e-03 9.53479431e-04 8.30449827e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.53787005e-05 4.61361015e-05 6.15148020e-05 0.00000000e+00\n",
      "  0.00000000e+00 4.61361015e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 9.22722030e-05\n",
      "  0.00000000e+00 1.56862745e-03 3.13725490e-03 2.70665129e-03 2.06074587e-03 2.21453287e-03 1.89158016e-03 3.53710111e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.84544406e-04\n",
      "  1.53787005e-04 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.38369858e-03 3.62937332e-03 3.18339100e-03 2.73740869e-03 1.64552095e-03 2.39907728e-03 2.47597078e-03 1.67627835e-03 9.84236832e-04 3.53710111e-04 1.18415994e-03 1.99923106e-03\n",
      "  1.10726644e-03 2.30680507e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.53787005e-05 0.00000000e+00\n",
      "  1.06113033e-03 3.18339100e-03 3.42945021e-03 3.35255671e-03 3.32179931e-03 3.32179931e-03 2.50672818e-03 1.95309496e-03 1.86082276e-03 1.87620146e-03 2.24529027e-03 2.16839677e-03 1.35332564e-03\n",
      "  2.64513649e-03 1.01499423e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.53787005e-05 1.53787005e-05 1.53787005e-05 0.00000000e+00\n",
      "  3.07574010e-03 3.56785852e-03 3.56785852e-03 3.58323722e-03 3.52172241e-03 3.42945021e-03 3.42945021e-03 3.30642061e-03 3.27566321e-03 2.52210688e-03 1.95309496e-03 1.89158016e-03 3.01422530e-03\n",
      "  3.52172241e-03 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  2.81430219e-03 3.46020761e-03 3.32179931e-03 3.42945021e-03 3.50634371e-03 3.61399462e-03 3.49096501e-03 3.44482891e-03 3.41407151e-03 3.44482891e-03 3.39869281e-03 3.42945021e-03 3.76778162e-03\n",
      "  2.66051519e-03 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  2.96808920e-03 3.50634371e-03 3.35255671e-03 3.27566321e-03 3.04498270e-03 2.76816609e-03 3.26028451e-03 3.22952710e-03 3.24490581e-03 3.27566321e-03 3.42945021e-03 3.38331411e-03 3.73702422e-03\n",
      "  3.10649750e-03 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.53787005e-05 4.61361015e-05 0.00000000e+00 1.84544406e-04\n",
      "  3.36793541e-03 3.38331411e-03 3.26028451e-03 3.35255671e-03 2.95271050e-03 2.59900038e-03 3.49096501e-03 3.19876970e-03 3.35255671e-03 3.44482891e-03 3.26028451e-03 3.47558631e-03 3.02960400e-03\n",
      "  3.21414840e-03 7.99692426e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 9.22722030e-05 0.00000000e+00 1.52249135e-03\n",
      "  3.75240292e-03 3.41407151e-03 3.38331411e-03 3.35255671e-03 3.12187620e-03 3.04498270e-03 3.39869281e-03 3.30642061e-03 3.27566321e-03 3.41407151e-03 3.38331411e-03 3.76778162e-03 1.83006536e-03\n",
      "  2.56824298e-03 8.61207228e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 6.15148020e-05 0.00000000e+00 0.00000000e+00 8.45828527e-04\n",
      "  3.62937332e-03 3.50634371e-03 3.53710111e-03 3.50634371e-03 3.69088812e-03 3.56785852e-03 3.27566321e-03 3.35255671e-03 3.42945021e-03 3.59861592e-03 3.33717801e-03 3.33717801e-03 3.21414840e-03\n",
      "  1.41484045e-03 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.53787005e-05 6.15148020e-05 9.22722030e-05 1.07650903e-04 3.07574010e-05 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 3.64475202e-03\n",
      "  3.47558631e-03 3.33717801e-03 3.42945021e-03 3.41407151e-03 3.36793541e-03 3.41407151e-03 3.39869281e-03 3.32179931e-03 3.42945021e-03 3.52172241e-03 3.30642061e-03 3.35255671e-03 3.92156863e-03\n",
      "  1.18415994e-03 0.00000000e+00]\n",
      " [0.00000000e+00 4.61361015e-05 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 9.53479431e-04 2.22991157e-03 3.13725490e-03 3.50634371e-03\n",
      "  3.18339100e-03 3.27566321e-03 3.39869281e-03 3.35255671e-03 3.19876970e-03 3.24490581e-03 3.35255671e-03 3.44482891e-03 3.42945021e-03 3.36793541e-03 3.30642061e-03 3.44482891e-03 3.75240292e-03\n",
      "  2.44521338e-03 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.76816609e-04 6.76662822e-04 1.26105344e-03 1.64552095e-03 2.90657439e-03 3.50634371e-03 3.38331411e-03 3.41407151e-03 3.33717801e-03\n",
      "  3.47558631e-03 3.07574010e-03 3.15263360e-03 3.24490581e-03 3.53710111e-03 3.44482891e-03 3.59861592e-03 2.70665129e-03 2.89119569e-03 3.84467512e-03 3.81391772e-03 3.58323722e-03 3.66013072e-03\n",
      "  3.30642061e-03 0.00000000e+00]\n",
      " [0.00000000e+00 8.76585928e-04 2.87581699e-03 3.19876970e-03 3.44482891e-03 3.39869281e-03 3.44482891e-03 3.19876970e-03 3.13725490e-03 3.29104191e-03 3.19876970e-03 3.21414840e-03 3.07574010e-03\n",
      "  2.44521338e-03 3.76778162e-03 2.96808920e-03 3.16801230e-03 3.42945021e-03 3.92156863e-03 3.92156863e-03 3.39869281e-03 3.59861592e-03 3.39869281e-03 3.24490581e-03 3.38331411e-03 3.56785852e-03\n",
      "  3.78316032e-03 0.00000000e+00]\n",
      " [4.61361015e-05 3.10649750e-03 3.50634371e-03 3.44482891e-03 3.39869281e-03 3.24490581e-03 3.24490581e-03 3.29104191e-03 3.15263360e-03 3.15263360e-03 3.15263360e-03 3.38331411e-03 3.69088812e-03\n",
      "  1.23029604e-03 2.30680507e-03 3.92156863e-03 3.52172241e-03 3.39869281e-03 2.89119569e-03 2.36831988e-03 2.93733180e-03 3.22952710e-03 3.13725490e-03 3.21414840e-03 3.41407151e-03 3.50634371e-03\n",
      "  3.46020761e-03 0.00000000e+00]\n",
      " [1.50711265e-03 3.58323722e-03 3.04498270e-03 3.22952710e-03 3.41407151e-03 3.52172241e-03 3.52172241e-03 3.59861592e-03 3.82929642e-03 3.38331411e-03 2.98346790e-03 3.30642061e-03 3.33717801e-03\n",
      "  3.70626682e-03 9.99615532e-04 1.12264514e-03 1.63014225e-03 1.79930796e-03 2.58362168e-03 3.36793541e-03 3.39869281e-03 3.30642061e-03 3.33717801e-03 3.42945021e-03 3.42945021e-03 3.44482891e-03\n",
      "  3.52172241e-03 4.45982314e-04]\n",
      " [1.15340254e-03 3.13725490e-03 3.26028451e-03 3.13725490e-03 2.96808920e-03 3.15263360e-03 3.24490581e-03 3.46020761e-03 3.32179931e-03 2.84505959e-03 3.02960400e-03 3.16801230e-03 3.04498270e-03\n",
      "  3.27566321e-03 3.69088812e-03 2.99884660e-03 3.49096501e-03 3.76778162e-03 3.67550942e-03 3.42945021e-03 3.35255671e-03 3.26028451e-03 3.21414840e-03 3.41407151e-03 3.38331411e-03 3.39869281e-03\n",
      "  3.53710111e-03 1.03037293e-03]\n",
      " [7.38177624e-04 3.12187620e-03 2.81430219e-03 2.98346790e-03 3.27566321e-03 3.02960400e-03 2.84505959e-03 2.92195309e-03 2.98346790e-03 2.95271050e-03 3.10649750e-03 3.29104191e-03 3.36793541e-03\n",
      "  3.39869281e-03 3.38331411e-03 3.62937332e-03 3.46020761e-03 3.32179931e-03 3.06036140e-03 3.16801230e-03 2.86043829e-03 2.78354479e-03 2.72202999e-03 2.64513649e-03 2.78354479e-03 3.15263360e-03\n",
      "  3.16801230e-03 1.76855056e-03]\n",
      " [0.00000000e+00 1.87620146e-03 3.36793541e-03 2.96808920e-03 2.75278739e-03 2.62975779e-03 2.81430219e-03 3.01422530e-03 3.13725490e-03 3.22952710e-03 3.27566321e-03 3.18339100e-03 3.24490581e-03\n",
      "  3.22952710e-03 3.07574010e-03 3.01422530e-03 2.98346790e-03 2.93733180e-03 2.99884660e-03 2.93733180e-03 3.04498270e-03 2.95271050e-03 2.70665129e-03 2.39907728e-03 2.56824298e-03 2.72202999e-03\n",
      "  3.22952710e-03 1.41484045e-03]\n",
      " [0.00000000e+00 0.00000000e+00 1.13802384e-03 2.90657439e-03 3.26028451e-03 2.93733180e-03 2.69127259e-03 2.64513649e-03 2.69127259e-03 2.78354479e-03 2.84505959e-03 2.89119569e-03 2.90657439e-03\n",
      "  2.89119569e-03 2.96808920e-03 3.04498270e-03 3.13725490e-03 3.21414840e-03 3.22952710e-03 3.22952710e-03 3.24490581e-03 2.89119569e-03 2.89119569e-03 2.98346790e-03 2.95271050e-03 3.32179931e-03\n",
      "  2.61437908e-03 0.00000000e+00]\n",
      " [3.07574010e-05 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.01499423e-03 3.07574010e-03 3.41407151e-03 3.64475202e-03 3.67550942e-03 3.72164552e-03 3.78316032e-03 3.73702422e-03 3.75240292e-03\n",
      "  3.39869281e-03 3.38331411e-03 2.96808920e-03 2.93733180e-03 2.75278739e-03 2.79892349e-03 2.79892349e-03 2.78354479e-03 2.70665129e-03 2.55286428e-03 2.58362168e-03 1.52249135e-03 8.91964629e-04\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 6.15148020e-04 9.38100730e-04 6.76662822e-04 1.10726644e-03 6.30526720e-04 5.38254517e-04\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(training_labels[0])\n",
    "print(training_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 1s 680us/step - loss: 0.4722 - accuracy: 0.8334\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 701us/step - loss: 0.4565 - accuracy: 0.8394\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 680us/step - loss: 0.4442 - accuracy: 0.8433\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 686us/step - loss: 0.4349 - accuracy: 0.8464\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 711us/step - loss: 0.4264 - accuracy: 0.8502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ae9d53c288>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_images, training_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 475us/step - loss: 0.4568 - accuracy: 0.8368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.456775426864624, 0.8367999792098999]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "classifications\n",
    "classifications.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_labels[5])\n",
    "print(test_labels[3])\n",
    "test_labels.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2177996e-03 9.9446493e-01 4.7706027e-04 1.0396142e-03 2.7001167e-03 3.1109015e-11 9.9810190e-05 1.5089819e-09 7.6270948e-07 5.8088263e-11]\n",
      "[9.0277790e-06 9.9947530e-01 1.7818938e-05 4.3830281e-04 5.8722391e-05 2.6497990e-10 6.9796238e-07 5.5191411e-09 1.1217933e-08 4.2951132e-10]\n"
     ]
    }
   ],
   "source": [
    "print(classifications[5])\n",
    "print(classifications[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 1s 651us/step - loss: 0.4272 - accuracy: 0.8782\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 644us/step - loss: 0.1222 - accuracy: 0.9642\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 652us/step - loss: 0.0781 - accuracy: 0.9770\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 659us/step - loss: 0.0578 - accuracy: 0.9820\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 661us/step - loss: 0.0417 - accuracy: 0.9873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1aea42e7f88>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "#model.compile(optimizer = 'adam',\n",
    "#              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 488us/step - loss: 0.0744 - accuracy: 0.9777\n",
      "[2.32871699e-07 1.57092703e-08 1.36796807e-05 2.73757032e-04 2.46798090e-12 1.33130991e-08 8.36057298e-13 9.99700904e-01 2.82526315e-07 1.11897925e-05]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 1s 586us/step - loss: 0.4985\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 609us/step - loss: 0.1568\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 593us/step - loss: 0.1058\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 590us/step - loss: 0.0828\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 597us/step - loss: 0.0642\n",
      "313/313 [==============================] - 0s 427us/step - loss: 0.0920\n",
      "[1.23389469e-07 7.03915481e-10 5.32570766e-07 2.40004956e-05 2.71930728e-10 2.72036971e-07 1.02263805e-11 9.99970317e-01 7.45785599e-07 4.05883793e-06]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3223\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0779\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0495\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0369\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0277\n",
      "313/313 [==============================] - 0s 577us/step - loss: 0.0875\n",
      "[3.5366189e-12 1.5690794e-10 1.8863686e-09 3.8558866e-08 5.4433884e-12 3.8539540e-11 3.1024405e-17 9.9999940e-01 1.0281140e-12 6.2900489e-07]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "Epoch 1/30\n",
      "1875/1875 [==============================] - 1s 668us/step - loss: 0.4251 - accuracy: 0.8812\n",
      "Epoch 2/30\n",
      "1875/1875 [==============================] - 1s 656us/step - loss: 0.1175 - accuracy: 0.9656\n",
      "Epoch 3/30\n",
      "1875/1875 [==============================] - 1s 669us/step - loss: 0.0770 - accuracy: 0.9764\n",
      "Epoch 4/30\n",
      "1875/1875 [==============================] - 1s 668us/step - loss: 0.0557 - accuracy: 0.9834\n",
      "Epoch 5/30\n",
      "1875/1875 [==============================] - 1s 665us/step - loss: 0.0420 - accuracy: 0.9871\n",
      "Epoch 6/30\n",
      "1875/1875 [==============================] - 1s 670us/step - loss: 0.0313 - accuracy: 0.9904\n",
      "Epoch 7/30\n",
      "1875/1875 [==============================] - 1s 660us/step - loss: 0.0254 - accuracy: 0.9927\n",
      "Epoch 8/30\n",
      "1875/1875 [==============================] - 1s 658us/step - loss: 0.0200 - accuracy: 0.9938\n",
      "Epoch 9/30\n",
      "1875/1875 [==============================] - 1s 668us/step - loss: 0.0147 - accuracy: 0.9958\n",
      "Epoch 10/30\n",
      "1875/1875 [==============================] - 1s 659us/step - loss: 0.0142 - accuracy: 0.9955\n",
      "Epoch 11/30\n",
      "1875/1875 [==============================] - 1s 662us/step - loss: 0.0108 - accuracy: 0.9967\n",
      "Epoch 12/30\n",
      "1875/1875 [==============================] - 1s 677us/step - loss: 0.0090 - accuracy: 0.9975\n",
      "Epoch 13/30\n",
      "1875/1875 [==============================] - 1s 664us/step - loss: 0.0073 - accuracy: 0.9982\n",
      "Epoch 14/30\n",
      "1875/1875 [==============================] - 1s 667us/step - loss: 0.0073 - accuracy: 0.9978\n",
      "Epoch 15/30\n",
      "1875/1875 [==============================] - 1s 663us/step - loss: 0.0073 - accuracy: 0.9974\n",
      "Epoch 16/30\n",
      "1875/1875 [==============================] - 1s 661us/step - loss: 0.0049 - accuracy: 0.9986\n",
      "Epoch 17/30\n",
      "1875/1875 [==============================] - 1s 671us/step - loss: 0.0077 - accuracy: 0.9975\n",
      "Epoch 18/30\n",
      "1875/1875 [==============================] - 1s 660us/step - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 19/30\n",
      "1875/1875 [==============================] - 1s 661us/step - loss: 0.0057 - accuracy: 0.9983\n",
      "Epoch 20/30\n",
      "1875/1875 [==============================] - 1s 667us/step - loss: 0.0061 - accuracy: 0.9980\n",
      "Epoch 21/30\n",
      "1875/1875 [==============================] - 1s 661us/step - loss: 0.0045 - accuracy: 0.9987\n",
      "Epoch 22/30\n",
      "1875/1875 [==============================] - 1s 671us/step - loss: 0.0039 - accuracy: 0.9988\n",
      "Epoch 23/30\n",
      "1875/1875 [==============================] - 1s 677us/step - loss: 0.0021 - accuracy: 0.9994\n",
      "Epoch 24/30\n",
      "1875/1875 [==============================] - 1s 659us/step - loss: 0.0046 - accuracy: 0.9984\n",
      "Epoch 25/30\n",
      "1875/1875 [==============================] - 1s 671us/step - loss: 0.0028 - accuracy: 0.9992\n",
      "Epoch 26/30\n",
      "1875/1875 [==============================] - 1s 660us/step - loss: 0.0049 - accuracy: 0.9984\n",
      "Epoch 27/30\n",
      "1875/1875 [==============================] - 1s 668us/step - loss: 0.0029 - accuracy: 0.9991\n",
      "Epoch 28/30\n",
      "1875/1875 [==============================] - 1s 668us/step - loss: 0.0048 - accuracy: 0.9983\n",
      "Epoch 29/30\n",
      "1875/1875 [==============================] - 1s 662us/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 30/30\n",
      "1875/1875 [==============================] - 1s 674us/step - loss: 0.0044 - accuracy: 0.9984\n",
      "313/313 [==============================] - 0s 488us/step - loss: 0.1421 - accuracy: 0.9791\n",
      "[3.2072151e-27 1.2775241e-20 3.5185214e-16 1.9299142e-13 7.1538713e-33 1.3304238e-34 0.0000000e+00 1.0000000e+00 4.2629258e-21 1.1549264e-20]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=30)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[34])\n",
    "print(test_labels[34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 7.3075 - accuracy: 0.8703\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3099 - accuracy: 0.9393\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2792 - accuracy: 0.9427\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2602 - accuracy: 0.9465\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2270 - accuracy: 0.9529\n",
      "313/313 [==============================] - 0s 622us/step - loss: 0.3447 - accuracy: 0.9442\n",
      "[8.8276604e-24 9.2673325e-19 1.3990402e-12 2.3718711e-09 9.6038501e-17 3.7761803e-14 1.1081463e-36 1.0000000e+00 1.8514941e-16 2.1646029e-13]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "#training_images=training_images/255.0\n",
    "#test_images=test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "classifications = model.predict(test_images)\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.5888\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3660\n",
      "\n",
      "Reached 60% accuracy so cancelling training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1aea378cd08>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('loss')<0.4):\n",
    "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images/255.0\n",
    "test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
